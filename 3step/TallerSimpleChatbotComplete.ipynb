{"cells":[{"cell_type":"markdown","metadata":{"id":"XWq1DaIM_QsI"},"source":["# SetUp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnJI8YZt_4F-"},"outputs":[],"source":["%%capture\n","!git clone https://github.com/Ryuksito/chatbot.git\n","!pip install --upgrade keras-nlp"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9032,"status":"ok","timestamp":1726487313667,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"bqJ3yG4w_4WW","outputId":"5cf169d0-d17d-4f47-a581-4da9639c8e54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","import pathlib\n","import random\n","import string\n","import re\n","import numpy as np\n","import json\n","\n","import tensorflow.data as tf_data\n","import tensorflow.strings as tf_strings\n","import tensorflow as tf\n","\n","import keras\n","from keras import layers\n","from keras import ops\n","from keras.layers import TextVectorization\n","import keras_nlp"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1726487313669,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"uRGnc5qHAGhd"},"outputs":[],"source":["# Consts\n","\n","SEED = 42\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","DATASET_PATH = '/content/chatbot/data/instructions.json'\n","CORPUS_PATH = '/content/chatbot/data/corpus.txt'\n","VOCAB_PATH = '/content/chatbot/weights/vocab.txt'\n","METADATA_PATH = '/content/chatbot/weights/metadata.json'\n","EMBEDDINGS_PATH = '/content/chatbot/weights/embedding.weights.npy'\n","\n","MODEL_DIR = '/content/drive/MyDrive/Exposiciones/Chatbot/weights/chatbot_model/'\n","\n","VOCAB_SIZE = 15000\n","SEQ_LENGTH = 2**8\n","EMBED_DIM = 2**8\n","BATCH_SIZE = 2**6\n","TAKE = 100\n","LATENT_DIM = 2**11\n","NUM_LAYERS = 4\n","NUM_HEADS = 8\n","EPOCHS = 60\n","\n","\n","with open(VOCAB_PATH, 'r', encoding='utf-8') as file:\n","  VOCAB = file.read().split('\\n')\n","\n","def replace_first_zero(tensor, scalar):\n","    mask = tf.equal(tensor, 0)\n","\n","    indices = tf.where(mask)\n","    if tf.size(indices) == 0:\n","        print(tensor)\n","        raise ValueError(\"No se encontró un 0 en el tensor\")\n","\n","    first_zero_index = indices[0][0]\n","\n","    updated_tensor = tf.tensor_scatter_nd_update(tensor, [[first_zero_index]], [scalar])\n","\n","    return updated_tensor"]},{"cell_type":"markdown","metadata":{"id":"I99IJfdK_Rr2"},"source":["# Preprocesar los datos"]},{"cell_type":"markdown","metadata":{"id":"I3olBjrPPCPL"},"source":["## Cargar la capa de embeddings"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":193,"status":"ok","timestamp":1726487313856,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"ZkC4D4brPE63"},"outputs":[],"source":["weights = np.load(EMBEDDINGS_PATH)\n","embedding_layer = layers.Embedding(VOCAB_SIZE,\n","                      SEQ_LENGTH,\n","                      name=\"w2v_embedding\")\n","\n","# paso de forward para inicializar la capa\n","dummy_target = tf.zeros((1,), dtype=tf.int64)\n","embedding_layer(dummy_target)\n","\n","embedding_layer.set_weights([weights])\n","\n","embedding_layer.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"3WfoFzcPAp3l"},"source":["## Cargar el dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1567,"status":"ok","timestamp":1726487315422,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"aga_SfnVAsxB","outputId":"5277f1a4-17bc-4007-9f50-e6b1971ceaea"},"outputs":[{"output_type":"stream","name":"stdout","text":["sugiera un eslogan para una campaña de reciclaje.\n"," --> <bos> 1. \"reduce, reutiliza, recicla: juntos por un futuro más verde.\"\n","2. \"recicla hoy, para un mañana mejor.\"\n","3. \"¡convierte tu basura en tesoro - recicla!\"\n","4. \"recicla por el ciclo de vida.\"\n","5. \"ahorra recursos, recicla más.\" <eos>\n"]}],"source":["# Load Dataset\n","\n","with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n","  dataset = json.load(f)\n","\n","instructions = []\n","answers = []\n","\n","for i in range(len(dataset['data'])):\n","  instructions.append(\n","      dataset['data'][i]['instruction'].lower()\n","      )\n","  answers.append(\n","      '<bos> ' +\n","      dataset['data'][i]['answer'].lower()\n","      + ' <eos>'\n","      )\n","\n","# Imprimir datos\n","for i, a in zip(instructions[0:1], answers[0:1]):\n","  print(i + ' --> ' + a)"]},{"cell_type":"markdown","metadata":{"id":"ynRoGFWdBBLs"},"source":["## Cargar el tokenizer"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1726487315699,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"rC2BoekDBDPF"},"outputs":[],"source":["tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n","     vocabulary=VOCAB,\n","     lowercase=True,\n","     suffix_indicator='<pow>',\n","     oov_token='<unk>',\n","     sequence_length=SEQ_LENGTH + 1,\n","     special_tokens=['<bos>', '<eos>', '<sep>', '<mask>', '<unk>', '<pow>'],\n","     special_tokens_in_strings=True\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1726487315927,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"yHhy9JJkWOb0","outputId":"3ed7849c-5b80-40cb-d949-6ba2560d31e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 257)\n","(256,)\n","(256,)\n"]}],"source":["print(tokenizer(instructions[0:5])[:-1].shape)\n","print(tokenizer(answers[0])[:-1].shape)\n","print(tokenizer(answers[0])[1:].shape)"]},{"cell_type":"markdown","metadata":{"id":"oGbvJqq8_SEn"},"source":["# Dataset pipeline"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":8437,"status":"ok","timestamp":1726487324362,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"87pR5JHiBywu"},"outputs":[],"source":["def format_dataset(instruction, answer):\n","    instruction = tokenizer(instruction)\n","    answer = tokenizer(answer)\n","    return (\n","        {\n","            \"encoder_inputs\": instruction[:, :-1],\n","            \"decoder_inputs\": answer[:, :-1],\n","        },\n","        answer[:, 1:],\n","    )\n","\n","\n","def make_dataset(instructions, answers):\n","    dataset = tf_data.Dataset.from_tensor_slices((instructions, answers))\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.cache().shuffle(2048).prefetch(16)\n","\n","\n","train_ds = make_dataset(instructions, answers)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16743,"status":"ok","timestamp":1726487341102,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"9pCPOg5cCCh0","outputId":"975b9610-a80d-42c2-caa0-b2212ebc0527"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs[\"encoder_inputs\"].shape: (64, 256)\n","inputs[\"decoder_inputs\"].shape: (64, 256)\n","targets.shape: (64, 256)\n"]}],"source":["for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"RKDWZkH0_STe"},"source":["# Model Clases"]},{"cell_type":"markdown","metadata":{"id":"dP4efWbZXQ4v"},"source":["## Encoder"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1726487341102,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"jH8Fif7aXQTX"},"outputs":[],"source":["class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(dense_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n","        else:\n","            padding_mask = None\n","\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"dense_dim\": self.dense_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config"]},{"cell_type":"markdown","metadata":{"id":"hCECHJVLCJql"},"source":["## Positional Embedding"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1726487341103,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"boaQ7-rRCVMV"},"outputs":[],"source":["class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, features_embeddings, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","        self.features_embeddings = features_embeddings\n","\n","    def build(self):\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=self.vocab_size, output_dim=self.embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=self.sequence_length, output_dim=self.embed_dim\n","        )\n","\n","    def call(self, inputs):\n","        length = ops.shape(inputs)[-1]\n","        positions = ops.arange(0, length, 1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","\n","        embedded_features = self.features_embeddings(inputs)\n","        return embedded_tokens + embedded_positions + embedded_features\n","\n","    def compute_mask(self, inputs, mask=None):\n","        if mask is None:\n","            return None\n","        else:\n","            return ops.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"sequence_length\": self.sequence_length,\n","                \"vocab_size\": self.vocab_size,\n","                \"embed_dim\": self.embed_dim,\n","            }\n","        )\n","        return config"]},{"cell_type":"markdown","metadata":{"id":"4NR6j_COCNCO"},"source":["## Decoder"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726487341103,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"r3wxRWT6CeJV"},"outputs":[],"source":["\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [\n","                layers.Dense(latent_dim, activation=\"relu\"),\n","                layers.Dense(embed_dim),\n","            ]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n","            padding_mask = ops.minimum(padding_mask, causal_mask)\n","        else:\n","            padding_mask = None\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = ops.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = ops.arange(sequence_length)[:, None]\n","        j = ops.arange(sequence_length)\n","        mask = ops.cast(i >= j, dtype=\"int32\")\n","        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = ops.concatenate(\n","            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n","            axis=0,\n","        )\n","        return ops.tile(mask, mult)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update(\n","            {\n","                \"embed_dim\": self.embed_dim,\n","                \"latent_dim\": self.latent_dim,\n","                \"num_heads\": self.num_heads,\n","            }\n","        )\n","        return config\n"]},{"cell_type":"markdown","metadata":{"id":"VFRLRmfoZRsn"},"source":["# Crear, Compilar y Entrenar"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1106,"status":"ok","timestamp":1726487342202,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"azzUaN3UZaDd"},"outputs":[],"source":["\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(SEQ_LENGTH, VOCAB_SIZE, EMBED_DIM, embedding_layer)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(EMBED_DIM, LATENT_DIM, NUM_HEADS)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(SEQ_LENGTH, VOCAB_SIZE, EMBED_DIM, embedding_layer)(decoder_inputs)\n","x = TransformerDecoder(EMBED_DIM, LATENT_DIM, NUM_HEADS)(x, encoded_seq_inputs)\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","chatbot = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726487342203,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"hR7YNr5EbHg0","outputId":"72edd0b1-6a74-4256-ad3a-bc1354f665d6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m7,745,536\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │     \u001b[38;5;34m16,860,056\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n","│                           │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,745,536</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n","├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n","│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,860,056</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n","│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,921,048\u001b[0m (91.25 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,921,048</span> (91.25 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,081,048\u001b[0m (76.60 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,081,048</span> (76.60 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,840,000\u001b[0m (14.65 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> (14.65 MB)\n","</pre>\n"]},"metadata":{}}],"source":["\n","chatbot.summary()\n","\n","chatbot.compile(\n","    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":91273,"status":"ok","timestamp":1726485695434,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"wiT3C5aJbqYD","outputId":"503d8668-1736-4ea5-b6eb-a1d3b8e30800"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 58s/step - accuracy: 0.0000e+00 - loss: 9.6953\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x786e02d713c0>"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["early_stopping = keras.callbacks.EarlyStopping(monitor='loss',patience=5, restore_best_weights=True)\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n","check_point = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=os.path.join(MODEL_DIR, \"weights\" + \"_epoch_{epoch}\" + '.weights.h5'),\n","        monitor=\"loss\",\n","        save_best_only=False,\n","        save_weights_only=True,\n","    )\n","\n","\n","chatbot.fit(train_ds.take(1), epochs=EPOCHS//EPOCHS, callbacks=[early_stopping, tensorboard_callback, check_point])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iGIZWrrJlLvG"},"source":["# Decodificar"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1726487826142,"user":{"displayName":"Alan_twt","userId":"10060741533168240015"},"user_tz":300},"id":"pB2DhYjilOJE"},"outputs":[],"source":["vocab = tokenizer.get_vocabulary()\n","index_lookup = dict(zip(range(VOCAB_SIZE), vocab))\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = tokenizer(input_sentence)[:-1]\n","    decoded_sentence = \"<start>\"\n","    tokenized_target_sentence = tokenizer(decoded_sentence)[:-1]\n","\n","    print('Chatbot:', end='')\n","\n","    for i in range(tf.where(tf.not_equal(tokenized_target_sentence, 0)).shape[0], SEQ_LENGTH):\n","\n","        predictions = chatbot([tokenized_input_sentence[None, :], tokenized_target_sentence[None, :]])\n","\n","        sampled_token_index = ops.convert_to_numpy(\n","            ops.argmax(predictions[0, i, :])\n","        ).item(0)\n","\n","        tokenized_target_sentence = replace_first_zero(tokenized_target_sentence, sampled_token_index)\n","\n","        sampled_token = index_lookup[sampled_token_index]\n","        if '<pow>' in sampled_token:\n","          sampled_token = sampled_token.replace('<pow>', '')\n","        else:\n","          if (i+1) % 8 == 0:\n","            sampled_token = sampled_token + '\\n'\n","          else:\n","              sampled_token = ' ' + sampled_token\n","\n","        print(sampled_token, end='')\n","\n","        if sampled_token == \"<end>\":\n","            break\n","    return tokenized_target_sentence\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8hi755qmlY9O"},"outputs":[],"source":["input_sentence = input('User: ').lower()\n","\n","try:\n","  out_tokenized_text = decode_sequence(input_sentence)\n","except KeyboardInterrupt:\n","  print('\\n End Chat')"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["I99IJfdK_Rr2","I3olBjrPPCPL","oGbvJqq8_SEn","RKDWZkH0_STe"],"authorship_tag":"ABX9TyNrE2gG7P8Apl6RwFfAfukr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}